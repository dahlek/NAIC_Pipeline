{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses results from aperture photometry to derive the optical depth of the atmosphere for a given night of observing.\n",
    "Does the following:\n",
    "- Fits star flux as a function of airmass to find an average optical depth as a function of wavelength for the night.\n",
    "\n",
    "Still needs to be added to notebook:\n",
    "- Uses optical depth with each star cube to find an F_top for each star cube\n",
    "- Takes the median of F_top\n",
    "- Uses F_top to find beta (photometric conversion factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi, r_\n",
    "from astropy.io import fits\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import interpolate\n",
    "from scipy import optimize\n",
    "from collections import OrderedDict\n",
    "from uncertainties import ufloat\n",
    "from uncertainties.umath import *  # sin(), etc.\n",
    "#>>> x = ufloat(1, 0.1)  # x = 1+/-0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F_obs(chi,tau,F_top):\n",
    "    # Function to use with curve_fit() to get tau\n",
    "    # F_top falls off with -tau*chi to give you F_obs\n",
    "    return F_top*np.e**(-tau*chi)\n",
    "\n",
    "def Ftop(chi,tau,F_obs):\n",
    "    # returns the flux at the top of the atmosphere by correcting for the atm\n",
    "    return F_obs*np.e**(tau*chi)\n",
    "\n",
    "def flux1(mag1,mag2,flux2):\n",
    "    # Useful for returning the flux of a star if it were scaled to Vega's magnitude.\n",
    "    # flux1 = Star's flux as Vega\n",
    "    # flux2 = Star's measured flux\n",
    "    # mag1 = Vega's flux\n",
    "    # mag2 = Star's flux\n",
    "    return flux2*(10**(0.4*(mag2-mag1)))\n",
    "\n",
    "def flux_relative_to_vega(mag2,flux2):\n",
    "    # Same as flux1, but with Vega's magnitude hard-coded.\n",
    "    # returns Star's flux as Vega\n",
    "    # flux2 = Star's measured flux\n",
    "    # mag2 = Star's flux\n",
    "    mag1 = 0.03 # Vega's V magnitude\n",
    "    return flux2*(10**(0.4*(mag2-mag1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Find the optical depth of the atmosphere for the night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tau_flux_fit(science_directory, science_list, starlist_directory, star_directory, snr_limit, wl_range):\n",
    "    \n",
    "    # science_directory = location of Jupiter cube\n",
    "    # science_list = location+name of Jupiter image list\n",
    "    # starlist_directory = location of image name lists for each cube. !!Assumes that name of star image lists are star1, star2, etc.\n",
    "    # star_directory = location of star fits files\n",
    "    # snr_limit = won't include fluxes below that range while calculating tau (previously used ~25)\n",
    "    # tau_fit_wl_range = range of wl in nm that's considered by the program when fitting a given wl point (typical values 2-5)\n",
    "    # Note: there are values for snr_limit and wl_range in Paul's thesis, but they might not be directly applicable to our observations. There's a trade-off between wavelength range and SNR in order to provide the function with enough data points to fit. Lower wl range needs a lower SNR, and vice versa. Values I used for March 2017 were snr_limit = 25, wl_range=8.\n",
    "    \n",
    "    # Make sure standard stars don't have significant reddening (that V mag is approximately average/representative of other magnitudes)\n",
    "    # Star lists need to be named star1, star2, etc.\n",
    "    # Doesn't require that you saved files of star flux from Ap_phot\n",
    "    \n",
    "    # Pulls information from star cubes, assuming they've already been through Ap_phot. Uses airmass, flux, and magnitude information to scale the stars to Vega, calculate an \n",
    "    \n",
    "    tau = []\n",
    "    tau_error = []\n",
    "    \n",
    "    # Quieries:\n",
    "    num_stars = raw_input('How many individual stars were imaged? ')\n",
    "        \n",
    "    num_cubes = int(raw_input('How many total cubes are there? '))\n",
    "    \n",
    "    V_mags = []\n",
    "    for i in range(0,int(num_cubes)):\n",
    "        mags = raw_input('For cube '+str(i+1)+', what is it\\'s V magnitude? ')\n",
    "        V_mags.append(float(mags)) # will be same length of number of star cubes\n",
    "    \n",
    "    photometric_quality_query = raw_input('If photometric info (keyword PHOTTEST) is saved in the header, do you want to save that information? y/n ')\n",
    "    \n",
    "    airmass_plot_query = raw_input('Do you want to see a plot of airmasses for all of the star cubes? y/n ')\n",
    "    snr_plot_query = raw_input('Do you want to see a plot of the SNR spectrum for each star cube? y/n ')\n",
    "    flux_plot_query = raw_input('Do you want to see a plot of the stars\\'s flux? y/n ')\n",
    "    tau_plot_query = raw_input('Do you want to see plots of optical depth fits for each wavelength? (warning: can slow down the fitting process quite a bit) y/n ')\n",
    "    \n",
    "    \n",
    "    wl_sci = np.linspace(470,950,241) # These are the wavelengths that tau will be derived for\n",
    "    \n",
    "    # Pull wavelengths tau will be fit at. In the case of these wavelengths being different than wl_sci, will be returned as a third output.\n",
    "    print 'Pulling wavelength array from science images...'\n",
    "    tau_wl = []\n",
    "    sciencelist = np.loadtxt(science_list,dtype=str)\n",
    "    for i in range(0,len(sciencelist)):\n",
    "        im = fits.open(science_directory+sciencelist[i])\n",
    "        if im[0].header['rfon'] == 1:\n",
    "            tau_wl.append(im[0].header['lambda'])\n",
    "        im.close()\n",
    "    \n",
    "    print 'Making dictionaries... '\n",
    "    \n",
    "    # load star lists into dictionaries\n",
    "    star_list_dict = OrderedDict()\n",
    "    for i in range(0,num_cubes):\n",
    "        star_list_dict['star'+str(i+1)+'_list'] = np.loadtxt(starlist_directory+'star'+str(i+1),dtype=str) # appends star lists in the wrong direction, but okay as long as we're consistent\n",
    "        \n",
    "    \n",
    "    # Pull airmasses, wavelengths, star flux, and snr of each image from from each image header from each cube and assign them to a dictionary\n",
    "    \n",
    "    # Make empty dictionaries\n",
    "    airmass_dict = OrderedDict(); airmass_wl_dict = OrderedDict(); star_snr_dict = OrderedDict(); star_flux_dict = OrderedDict()\n",
    "    \n",
    "    # pulling these for plotting purposes\n",
    "    for i in range(0,len(star_list_dict)):\n",
    "        airmass_list = []; airmass_wl_list = []; star_snr_list = []; star_flux_list = []\n",
    "        for j in star_list_dict['star'+str(i+1)+'_list']: # for each star cube\n",
    "            #print j # Each image in the list\n",
    "            im = fits.open(star_directory+str(j))\n",
    "            if im[0].header['rfon'] == 1:\n",
    "                airmass_list.append(im[0].header['airmass'])\n",
    "                airmass_wl_list.append(im[0].header['lambda'])\n",
    "                star_snr_list.append(im[0].header['star_snr'])    \n",
    "                star_flux_list.append(im[0].header['star_flx'])\n",
    "            im.close()\n",
    "        airmass_dict['airmass_star'+str(i+1)] = airmass_list # dictionary of airmasses\n",
    "        airmass_wl_dict['airmass_wl_star'+str(i+1)] = airmass_wl_list # dictionary of wavelngths corresponding to airmasses (and other qualities appended above)\n",
    "        star_snr_dict['snr_star'+str(i+1)] = star_snr_list # dictionary of SNR\n",
    "        star_flux_dict['flux_star'+str(i+1)] = star_flux_list # dictionary of star flux\n",
    "        \n",
    "    # Plot airmass coverage\n",
    "    if airmass_plot_query == 'y':\n",
    "        for j in range(0,len(airmass_dict)):\n",
    "            plt.plot(airmass_dict['airmass_star'+str(j+1)], airmass_wl_dict['airmass_wl_star'+str(j+1)],'.')\n",
    "        plt.title('Airmass coverage')\n",
    "        plt.ylabel('Wavelength')\n",
    "        plt.xlabel('Airmass')\n",
    "        plt.legend(airmass_dict.keys())\n",
    "        plt.show()\n",
    "        \n",
    "    # Plot SNR spectra\n",
    "    if snr_plot_query == 'y':\n",
    "        for j in range(0,len(airmass_wl_dict)):\n",
    "            plt.plot(airmass_wl_dict['airmass_wl_star'+str(j+1)], star_snr_dict['snr_star'+str(j+1)], '.')\n",
    "        plt.title('SNR of All Cubes')\n",
    "        plt.ylabel('SNR')\n",
    "        plt.xlabel('Wavelength')\n",
    "        plt.legend(star_snr_dict.keys())\n",
    "        plt.show()\n",
    "        \n",
    "    # Plot flux spectra\n",
    "    if flux_plot_query == 'y':\n",
    "        for j in range(0,len(airmass_wl_dict)):\n",
    "            plt.plot(airmass_wl_dict['airmass_wl_star'+str(j+1)], star_flux_dict['flux_star'+str(j+1)])\n",
    "        plt.title('Star Flux')\n",
    "        plt.ylabel('Flux (counts/sec)')\n",
    "        plt.xlabel('Wavelength')\n",
    "        plt.legend(star_flux_dict.keys())\n",
    "        plt.show()\n",
    "                \n",
    "    # Scale spectra to Vega's magntiude and plot them\n",
    "    for j in range(0,len(airmass_wl_dict)):\n",
    "        plt.plot(airmass_wl_dict['airmass_wl_star'+str(j+1)],\\\n",
    "        flux_relative_to_vega(V_mags[j],np.array(star_flux_dict['flux_star'+str(j+1)])))\n",
    "    plt.title('Fluxes scaled to Vega')\n",
    "    plt.ylabel('DN/sec')\n",
    "    plt.xlabel('Wavelength')\n",
    "    plt.show()\n",
    "    \n",
    "    # save photometric test if done previously/desired (not a lot of evidence accounting for this improves photometric cal in the end)\n",
    "    if photometric_quality_query == 'y':\n",
    "        phot_qual_dict = OrderedDict()\n",
    "        for i in range(0,len(star_list_dict)):\n",
    "            phot_qual_list = []\n",
    "            for j in star_list_dict['star'+str(i+1)+'_list']: # for each star cube\n",
    "                im = fits.open(star_directory+str(j))\n",
    "                if im[0].header['rfon'] == 1:\n",
    "                    phot_qual_list.append(im[0].header['phottest']) # 1 if photometric, 0 if not.\n",
    "                im.close()\n",
    "            phot_qual_dict['phot_qual_star'+str(i+1)] = phot_qual_list # dictionary of airmasses\n",
    "            \n",
    "            \n",
    "    print 'Finding an average tau value...'\n",
    "    \n",
    "    \n",
    "    # Find tau for each science wavelength\n",
    "    for i in range(0,len(wl_sci)):\n",
    "        \n",
    "        #print 'Fitting optical depth at '+str(wl_sci[i])+' nm ...'\n",
    "        \n",
    "        if i%12 == 0:\n",
    "            print str(int(100*i/241.))+'% complete'\n",
    "        \n",
    "        flux = []\n",
    "        airmass = []\n",
    "        \n",
    "         # loop through cubes\n",
    "        for k in range(0,len(star_list_dict)):\n",
    "            \n",
    "            # loop through each image for a given cube\n",
    "            for j in range(0,len(star_list_dict['star'+str(k+1)+'_list'])): # for each star cube\n",
    "                im = fits.open(star_directory+str(star_list_dict['star'+str(k+1)+'_list'][j]))\n",
    "                if im[0].header['rfon'] == 1:\n",
    "                    if im[0].header['star_snr'] >= snr_limit:\n",
    "                        \n",
    "                        if photometric_quality_query == 'y':\n",
    "                            if im[0].header['phottest'] == 1:\n",
    "                                if im[0].header['lambda'] > (wl_sci[i]-wl_range) and im[0].header['lambda'] < (wl_sci[i]+wl_range):\n",
    "                                    flux.append(flux_relative_to_vega(V_mags[k], im[0].header['star_flx'])) # append Vega-scaled flux\n",
    "                                    airmass.append(im[0].header['airmass'])\n",
    "\n",
    "                        else:\n",
    "                            if im[0].header['lambda'] > (wl_sci[i]-wl_range) and im[0].header['lambda'] < (wl_sci[i]+wl_range):\n",
    "                                flux.append(flux_relative_to_vega(V_mags[k], im[0].header['star_flx'])) # append Vega-scaled flux\n",
    "                                airmass.append(im[0].header['airmass'])\n",
    "\n",
    "                im.close()\n",
    "        \n",
    "        # for a given wavelength, sort airmass and flux\n",
    "        dummy = np.zeros((len(airmass),2))\n",
    "        dummy[:,0] = airmass\n",
    "        dummy[:,1] = flux\n",
    "        dummy = sorted(dummy, key=lambda a_entry: a_entry[0])\n",
    "        \n",
    "        #Make them lists again\n",
    "        airmass_sorted = []\n",
    "        flux_sorted = []\n",
    "        for x in range(0,len(dummy)):\n",
    "            airmass_sorted.append(dummy[x][0])\n",
    "            flux_sorted.append(dummy[x][1])\n",
    "        \n",
    "        # Fit the values for a given wavelength using the equations defined previously\n",
    "        guess = np.array((0.01,1e3)) # Does this work??\n",
    "        popt, pcov = curve_fit(F_obs, airmass_sorted, flux_sorted,guess) # curve_fit(Function to fit, xdata, ydata)\n",
    "        \n",
    "        if tau_plot_query == 'y':\n",
    "            plt.plot(airmass_sorted, F_obs(np.array(airmass_sorted),*popt), 'r-', label='fit')\n",
    "            plt.plot(airmass_sorted, flux_sorted, 'b.', label='data')\n",
    "            plt.title(wl_sci[i])\n",
    "            plt.ylabel('flux')\n",
    "            plt.xlabel('airmass')\n",
    "            plt.show()\n",
    "        \n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        #print perr[0] # error on tau\n",
    "\n",
    "        #print 'tau: ',(popt[0]),'+-',perr[0],' ',wl_sci[i]\n",
    "        if popt[0] < 0:\n",
    "            print 'Warning!! Optical depth at '+str(wl_sci[i])+' less than 0.'\n",
    "        tau.append(popt[0])\n",
    "        tau_error.append(perr[0])\n",
    "        \n",
    "    # If wavelengths in images are different than wl_sci:\n",
    "    if tau_wl[0] != wl_sci[0]:\n",
    "        return tau, tau_error, tau_wl\n",
    "    else:\n",
    "        return tau, tau_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sample use:\n",
    "# Will return an additional output, tau_wl, if im[0].header['lambda'] aren't the same as np.inspace(470,950,241)\n",
    "tau,tau_error = tau_flux_fit('/Volumes/PAL/emmas_stuff/PJ19_data/jup1/',\\\n",
    "            '/Volumes/PAL/emmas_stuff/PJ19_data/juplist1',\\\n",
    "            '/Volumes/PAL/emmas_stuff/PJ19_data/',\\\n",
    "            '/Volumes/PAL/emmas_stuff/PJ19_data/reduced/',25,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_sci = np.linspace(470,950,241)\n",
    "plt.errorbar(wl_sci, tau, color='blue', ecolor='g', yerr=np.array(tau_error))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests - plotting Hannahs and original\n",
    "tau_orig = np.loadtxt('/Volumes/external_hd/march2017/redo/tau_march2017_noVir85')\n",
    "#tau = np.loadtxt('/Volumes/external_hd/march2017/redo/tau_march2017')\n",
    "\n",
    "plt.plot(tau_orig[:,0],tau_orig[:,1])\n",
    "hannah_tau = np.loadtxt('/Users/dahlek/Downloads/tau_march2017')\n",
    "plt.plot(hannah_tau[:,0],hannah_tau[:,1])\n",
    "plt.plot(wl_sci,tau)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tau and error to text file\n",
    "wl_sci = np.linspace(470,950,241)\n",
    "dummy = np.zeros((len(tau),3))\n",
    "dummy[:,0] = wl_sci#tau_wl\n",
    "dummy[:,1] = tau\n",
    "dummy[:,2] = tau_error\n",
    "np.savetxt('/Volumes/PAL/emmas_stuff/PJ19_data/tau_wl_error',dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Find a median F_top (cal star flux at the top of the atmosphere)\n",
    "\n",
    "Be sure to have tau and tau_error saved from Tau_flux_fit routine above; or, read it in from a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F_top_finder(starlist_directory, star_directory, F_vega, tau, tau_error, tau_wl=0):\n",
    "    # Uses optical depth to find flux at the top of the atmosphere for each star cube; uses those fluxes to find a median F_top. Science wavelengths are hard-coded for NAIC.\n",
    "    # starlist_directory = location of image name lists for each cube. !!Assumes that name of star image lists are star1, star2, etc.\n",
    "    # star_directory = location of star fits files\n",
    "    # F_vega - model Vega spectrum from http://kurucz.harvard.edu/stars/vega/, interpolated at NAIC wavelengths and convolved with NAIC filter functions\n",
    "    # tau, tau_error - from ap_phot\n",
    "    # tau_wl - ONLY include as an array in the instance of wavelengths in image headers being differnet than wl_sci (e.g. in the case of having corrected wavelengths in the headers)\n",
    "    \n",
    "    wl_sci = np.linspace(470,950,241)\n",
    "    \n",
    "    num_stars = raw_input('How many individual stars were imaged? ')\n",
    "        \n",
    "    num_cubes = int(raw_input('How many total cubes are there? '))\n",
    "    \n",
    "    V_mags = []\n",
    "    for i in range(0,int(num_cubes)):\n",
    "        mags = raw_input('For cube '+str(i+1)+', what is it\\'s V magnitude? ')\n",
    "        V_mags.append(float(mags)) # will be same length of number of star cubes\n",
    "        \n",
    "    F_top_plot_query = raw_input('Do you want to see plots of all of the calculated F_top? y/n ')\n",
    "    \n",
    "    # Set up errors\n",
    "    F_vega_with_error = []\n",
    "    for i in range(0,len(wl_sci)):\n",
    "        F_vega_with_error.append(ufloat(F_vega[i], 0.01*F_vega[i]))\n",
    "    \n",
    "    print 'Making dictionaries...'\n",
    "    # load star lists into dictionaries\n",
    "    star_list_dict = OrderedDict()\n",
    "    for i in range(0,num_cubes):\n",
    "        star_list_dict['star'+str(i+1)+'_list'] = np.loadtxt(starlist_directory+'star'+str(i+1),dtype=str)\n",
    "        \n",
    "    airmass_dict = OrderedDict(); airmass_wl_dict = OrderedDict()\n",
    "    # Pull airmasses from stars; make dictionary\n",
    "    for i in range(0,len(star_list_dict)):\n",
    "        airmass_list = []; airmass_wl_list = []\n",
    "        for j in star_list_dict['star'+str(i+1)+'_list']: # for each star cube\n",
    "            #print j # Each image in the list\n",
    "            im = fits.open(star_directory+str(j))\n",
    "            if im[0].header['rfon'] == 1:\n",
    "                airmass_list.append(im[0].header['airmass'])\n",
    "                airmass_wl_list.append(im[0].header['lambda'])\n",
    "            im.close()\n",
    "        airmass_dict['airmass_star'+str(i+1)] = airmass_list # dictionary of airmasses\n",
    "        airmass_wl_dict['airmass_wl_star'+str(i+1)] = airmass_wl_list # dictionary of wavelngths corresponding to airmasses (and other qualities appended above)\n",
    "    \n",
    "    \n",
    "    # Find F_top for each cube:\n",
    "    F_top_dict = OrderedDict(); beta_dict = OrderedDict()\n",
    "    for i in range(0,len(star_list_dict)):       \n",
    "        print 'Finding F_top and beta for cube '+str(i+1)+'...'\n",
    "        F_top_list = []\n",
    "        wl_tau_test = []\n",
    "        for j in range(0,len(star_list_dict['star'+str(i+1)+'_list'])): # for each star cube\n",
    "            im = fits.open(star_directory+str(star_list_dict['star'+str(i+1)+'_list'][j]))\n",
    "            if im[0].header['rfon'] == 1:\n",
    "                \n",
    "                \n",
    "                # Find the tau that equals the wavelength of the image\n",
    "                for k in range(0,len(wl_sci)):\n",
    "                    \n",
    "                    if np.array(tau_wl).any() != 0: # If the user included a wavelength array bc tau was derived at wavelengths other than wl_sci\n",
    "                        if wl_sci[k] == im[0].header['orig_wl']: \n",
    "                            optical_depth = tau[k]\n",
    "                            optical_depth_error = tau_error[k]\n",
    "                            wl_tau_test.append(wl_sci[k])\n",
    "                            \n",
    "                    else:\n",
    "                        if wl_sci[k] == im[0].header['lambda']:\n",
    "                            wl_tau_test.append(wl_sci[k])\n",
    "                            optical_depth = tau[k]\n",
    "                            optical_depth_error = tau_error[k]\n",
    "                        else:\n",
    "                            print 'no wavelength found'\n",
    "                            \n",
    "                        \n",
    "                # Calculate F_top, save it to a dictionary\n",
    "                tau_with_error = ufloat(optical_depth,optical_depth_error)\n",
    "                F_top_list.append( Ftop( im[0].header['airmass'], tau_with_error, flux_relative_to_vega(V_mags[i], im[0].header['star_flx'])) )\n",
    "                \n",
    "                \n",
    "        # Loop through F_top_list and average any duplicate wavelengths \n",
    "        if len(F_top_list) > len(wl_sci):\n",
    "            print 'Current F_top list contains duplicate wavelengths. Fixing...'\n",
    "            print 'Duplicates:', list(set([x for x in wl_tau_test if wl_tau_test.count(x) > 1]))\n",
    "            for p in range(0,len(list(set([x for x in wl_tau_test if wl_tau_test.count(x) > 1])))):\n",
    "                indeces = []\n",
    "                F_top_duplicate = []\n",
    "                for r in range(0,len(wl_tau_test)):\n",
    "                    if list(set([x for x in wl_tau_test if wl_tau_test.count(x) > 1]))[p] == wl_tau_test[r]:\n",
    "                        F_top_duplicate.append(F_top_list[r])\n",
    "                        indeces.append(r)\n",
    "                        \n",
    "                # Find average F_top of duplicates, save to the first instance where it appears \n",
    "                F_top_duplicate_mean = np.mean(F_top_duplicate)\n",
    "                F_top_list[indeces[0]] = F_top_duplicate_mean\n",
    "                for h in range(1,len(indeces)):\n",
    "                    del F_top_list[indeces[h]]\n",
    "                    \n",
    "                \n",
    "        beta_dict['beta'+str(i)] = F_vega_with_error/np.array(F_top_list)\n",
    "        F_top_dict['F_top_'+str(i)] = np.array(F_top_list)\n",
    "        \n",
    "        \n",
    "    # Plot F_tops if you want to\n",
    "    if F_top_plot_query == 'y':\n",
    "        for i in range(0,len(F_top_dict)):\n",
    "            ftop = []\n",
    "            for j in range(0,len(F_top_dict['F_top_'+str(i)])):\n",
    "                ftop.append(F_top_dict['F_top_'+str(i)][j].nominal_value)\n",
    "            plt.plot(wl_sci, ftop)\n",
    "        plt.ylabel('Flux, DN/sec')\n",
    "        plt.xlabel('Wavelength (nm)')\n",
    "        plt.title('F_top for each cube')\n",
    "        plt.legend(F_top_dict.keys())\n",
    "        plt.show()\n",
    "        \n",
    "    print 'Finding medians and seperating and saving nominal values and error...'    \n",
    "    \n",
    "    # calculate median F_top and beta from individual F_tops\n",
    "    F_top_median = []\n",
    "    for h in range(0,len(wl_sci)):\n",
    "        F_top_median_dummy = []\n",
    "        for j in range(0,len(F_top_dict)):\n",
    "            F_top_median_dummy.append(F_top_dict.values()[j][h])\n",
    "        F_top_median.append(np.median(F_top_median_dummy))\n",
    "        \n",
    "    # seperate and save values and error\n",
    "    F_top_median_nominal = []\n",
    "    F_top_median_error = []\n",
    "    for x in range(0,len(F_top_median)):\n",
    "        F_top_median_nominal.append(F_top_median[x].nominal_value)\n",
    "        F_top_median_error.append(F_top_median[x].std_dev)\n",
    "        \n",
    "    # Calculate the median beta value        \n",
    "    Beta_median = []\n",
    "    for h in range(0,len(wl_sci)):\n",
    "        Beta_median_dummy = []\n",
    "        for j in range(0,len(beta_dict)):\n",
    "            Beta_median_dummy.append(beta_dict.values()[j][h])\n",
    "        Beta_median.append(np.median(Beta_median_dummy))\n",
    "        \n",
    "    # seperate and save values and error\n",
    "    beta_nominal = []\n",
    "    beta_error = []\n",
    "    for x in range(0,len(Beta_median)):\n",
    "        beta_nominal.append(Beta_median[x].nominal_value)\n",
    "        beta_error.append(Beta_median[x].std_dev)\n",
    "        \n",
    "        \n",
    "    plt.plot(wl_sci,F_top_median_nominal)\n",
    "    plt.title('Median F_top value, scaled to Vega')\n",
    "    plt.ylabel('Flux, DN/sec')\n",
    "    plt.xlabel('Wavelength (nm)')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(wl_sci,beta_nominal)\n",
    "    plt.title('Beta')\n",
    "    plt.ylabel('(DN/sec)/(erg/sec/cm2/A)')\n",
    "    plt.show()\n",
    "    \n",
    "    # return median F_top and error \n",
    "    return F_top_median_nominal, F_top_median_error, beta_nominal, beta_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_V = np.loadtxt('/Volumes/PAL/emmas_stuff/PJ19_data/vega_and_solar_march2020filter_convolve')[:,1]\n",
    "tau = np.loadtxt('/Volumes/PAL/emmas_stuff/PJ19_data/tau_wl_error')[:,1]\n",
    "tau_error = np.loadtxt('/Volumes/PAL/emmas_stuff/PJ19_data/tau_wl_error')[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_top, f_top_error, beta_median, beta_median_error = F_top_finder('/Volumes/PAL/emmas_stuff/PJ19_data/reduced/',\\\n",
    "            '/Volumes/PAL/emmas_stuff/PJ19_data/reduced/', F_V, tau,tau_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save median F_top and error to a text file\n",
    "wl_sci = np.linspace(470,950,241)\n",
    "dummy = np.zeros((len(wl_sci),3))\n",
    "dummy[:,0] = wl_sci\n",
    "dummy[:,1] = f_top\n",
    "dummy[:,2] = f_top_error\n",
    "np.savetxt('/Volumes/PAL/emmas_stuff/PJ19_data/F_top_error',dummy)\n",
    "\n",
    "# save beta and error to a text file\n",
    "dummy = np.zeros((len(wl_sci),3))\n",
    "dummy[:,0] = wl_sci\n",
    "dummy[:,1] = beta_median\n",
    "dummy[:,2] = beta_median_error\n",
    "np.savetxt('/Volumes/PAL/emmas_stuff/PJ19_data/beta_error',dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
