{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidated data pipeline program. 2 parts (as of Jan. 6, 2019): flat prep, and science image reduction. In previous versions, those two steps are combined, but here (since Gaussian filter needs to be applied to flats after rf-off sub) seperated for flexibility's sake.\n",
    "\n",
    "Completes the following steps (some are optional):\n",
    "- Wavelength cal (if data is from before Jan. 2018)\n",
    "- Doppler shift correction for motion of planet (but not rotation)\n",
    "- Attaches ephemerides and telescope pointing info\n",
    "- Can create a pixel mask if you want\n",
    "- Corrects for hot pixels/cosmic rays\n",
    "- Divides by exposure time\n",
    "- Can correct for fringing\n",
    "- Applies Gaussian filter to noisy flats\n",
    "- Divides by flats\n",
    "- Subtracts RF-off images\n",
    "\n",
    "Before running:\n",
    "- Have completed science image list, for target and flats. This means, check for saturation, unbinned images, repeats beforehand. No wavelength repeats!\n",
    "- Have lists of ephemerides downloaded from JPL Horizons. \n",
    "- Have APO pointing logfile\n",
    "- Know if you need a pixel mask made or not. \n",
    "- Generally a good idea to saw a directory of the raw data in case of any mistakes\n",
    "\n",
    "How to run:\n",
    "1. Compile each subroutine\n",
    "2. Run flat_prep()\n",
    "3. Once flats have been reduced, run reduce_datacube()\n",
    "4. Check data manually to make sure everything worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.ndimage as ndimage\n",
    "from astropy.io import fits\n",
    "from scipy.ndimage import filters\n",
    "from astropy import units as u\n",
    "from astropy.nddata import CCDData\n",
    "import ccdproc\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions for correcting wavelengths of images taken before January 2018\n",
    "\n",
    "# Further work in 2019 showed that this correction isn't good and shouldn't be applied, regardless of when images were taken; but, if fringing frames (as developed by Erandi's program) were made using these 'corrected' wavelengths, you'll need to correct the wavelengths associated with the Jupiter and flat frames, since the fringing correction program checks wavelengths.\n",
    "\n",
    "def RF_function(wl):\n",
    "    '''Takes a wavelength value of an image, returns the RF value that should be used to generate that wavelength. '''\n",
    "    A1 = 0.152464324712792 \n",
    "    A2 = -0.249953566211374 \n",
    "    A3 = -0.168609021526478 \n",
    "    A4 = -1.26484658735496 \n",
    "    A5 = 6.59454398355950 \n",
    "    A6 = -23.6712903221411 \n",
    "    A7 = 101.932242630767\n",
    "    B1 = 724.867720000000\n",
    "    B2 = 144.671593361344\n",
    "    x = (wl-B1)/B2 # centering and scaling transformation\n",
    "    return A1*x**6 + A2*x**5 + A3*x**4 + A4*x**3 + A5*x**2 + A6*x + A7\n",
    "    \n",
    "def wl_finder(RF,read_wl):\n",
    "    '''Use wl and RF frequency array from RF() to interpolate between points and find wl from RF frequency and wl read from image header'''\n",
    "    #define wavelength space using read wavelength of image (10 nm on either side)\n",
    "    wl_space = np.linspace(read_wl-40,read_wl+40,10000)\n",
    "    #define function over that wavelength space\n",
    "    wl_func = interp1d(RF_function(wl_space),wl_space)\n",
    "    #return the wavelength at the input RF using interpolated function\n",
    "    return wl_func(RF)\n",
    "\n",
    "def wavelength_corrector(imagelist,directory):\n",
    "    '''Uses wl_finder() and RF_finction() to save actual wavelength to images'''\n",
    "    images = np.loadtxt(imagelist,dtype=str)\n",
    "    for i in range(0,len(images)):\n",
    "        #correcting both rf-off and rf-on images\n",
    "        im = fits.open(directory+images[i])\n",
    "        image_wavelength = im[0].header['lambda']\n",
    "        image_rf = im[0].header['rffreq']\n",
    "        actual_wavelength = round(float(wl_finder(image_rf,image_wavelength)),3)\n",
    "    \n",
    "        #save old and new wavelengths to header\n",
    "        im[0].header['ORIG_WL'] = (image_wavelength,'Original recorded wl')\n",
    "        im[0].header['LAMBDA'] = (actual_wavelength,'Corrected wl')\n",
    "        im.writeto(directory+images[i],overwrite=True)\n",
    "        im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doppler_shift_corr(imagelist,directory):\n",
    "    '''\n",
    "    Corrects wavelength for Jupiter's motion (but not its rotation)\n",
    "    \n",
    "    Directory = path of location of images\n",
    "    imlist = path+name of image list\n",
    "    '''\n",
    "    c = 3e5 # km/s\n",
    "    imlist = np.loadtxt(imagelist,dtype=str)\n",
    "    \n",
    "    for i in range(0,len(imlist)):\n",
    "        im = fits.open(directory+imlist[i])\n",
    "        if im[0].header['rfon'] == 1:\n",
    "            wl_naught = im[0].header['lambda'] #nm\n",
    "            v_r = im[0].header['pe_rate'] # km/s\n",
    "            \n",
    "            im[0].header['WLPREDOP'] = (wl_naught,'Wavelength before Doppler correction')\n",
    "            im[0].header['LAMBDA'] = (wl_naught*((v_r/c)+1),'Wavelength (nm)')\n",
    "            im[0].header['HISTORY'] = ('Wavelength corrected for Doppler shift')\n",
    "            im.writeto(directory+imlist[i],overwrite=True)\n",
    "        im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Depending on input used to make ephimerides file, can include RA and dec columns, which will affect column indeces. There are two options in the following program that account for these indeces changes. Be sure to check the columns being looked at match what this program is pulling out.\n",
    "\n",
    "def attach_eph(directory,image_file,eph_file):\n",
    "    '''\n",
    "    Attaches Jupiter's ephimerides information to the fits header.\n",
    "    \n",
    "    directory: where images to attach eph are located, where images will be saved to \n",
    "    image_file: location+name of list of images\n",
    "    eph_file: location+name of ephemerides file from horizons\n",
    "    \n",
    "    Make ephimerides file using https://ssd.jpl.nasa.gov/horizons.cgi\n",
    "    Settings for Horizons: (From Paul's program 'get_ephemeris.pro')\n",
    "    ; QUANTITIES= '4,8,11,13,14,15,17,19,20,21,24'\n",
    "    ;\n",
    "    ;  4. Apparent Azimuth & Elevation\n",
    "    ;  8. Airmass\n",
    "    ; 11. Defect of illumination\n",
    "    ; 13. Target angular diameter\n",
    "    ; 14. Obs sub-long & sub-lat\n",
    "    ; 15. Solar sub-long & sub-lat\n",
    "    ; 17. N. Pole Pos. Ang & Dis\n",
    "    ; 19. Helio range & range rate\n",
    "    ; 20. Observer range & range rate\n",
    "    ; 21. One-way light travel time\n",
    "    ; 24. Sun-Target-Observer angle\n",
    "\n",
    "    ; NOTE: Be sure to have the following table settings:\n",
    "    ;\t\t\t\t\tDate/Time: Julian Day\n",
    "    ;\t\t\t\t\tTime Digits: Fractional Seconds\n",
    "    ;\t\t\t\t\tOutput Units: km & km/s\n",
    "    ;\t\t\t\t\tRange Units: Kilometers\n",
    "    ;\t\t\t\t\tRefraction Model: AIRLESS\n",
    "    ;\t\t\t\t\tExtra Precision: YES\n",
    "    ;\t\t\t\t\tCVS Format: Yes\n",
    "    '''\n",
    "    \n",
    "    eph = np.loadtxt(eph_file,dtype=str,delimiter=',')\n",
    "    image_list = np.loadtxt(image_file,dtype=str)\n",
    "    \n",
    "    #Define empty lists of ephemerides\n",
    "    jd = []\n",
    "    RA = [] #hr min s\n",
    "    dec = [] #deg min s\n",
    "    az = [] #azimuth, degrees\n",
    "    alt = [] #altitude, degrees\n",
    "    airmass = [] #airmass\n",
    "    ext = [] #mag of extinction\n",
    "    def_ill = [] #defect of illumination (arcseconds)\n",
    "    angd = [] #angular diameter (arcseconds)\n",
    "    obs_long = [] #degrees\n",
    "    obs_lat = [] #degrees\n",
    "    sol_long = [] #degrees\n",
    "    sol_lat = [] #degrees\n",
    "    np_ang = [] #degrees and arcseconds\n",
    "    np_dist = [] #degrees and arcseconds\n",
    "    r = [] #km\n",
    "    rdot = [] #km/s\n",
    "    delta_r = [] #km\n",
    "    delta_rdot = [] #km/s\n",
    "    lt = [] #light travel time (minutes)\n",
    "    phase_angle = [] #(degrees)\n",
    "    \n",
    "    # make lists of each column: ********Convert data types??\n",
    "    for i in range(0,len(eph)):\n",
    "        \n",
    "        if len(eph[0]) == 21: # if RA and dec weren't included\n",
    "            ra_dec_index = 0\n",
    "        elif len(eph[0]) == 23: # if RA and dec are included\n",
    "            ra_dec_index = 2\n",
    "            RA.append(eph[i][3])\n",
    "            dec.append(eph[i][4])\n",
    "        \n",
    "        if eph[i][5+ra_dec_index] == '   n.a.': #ignore airmass and the rest of the values if no airmass (Jupiter is below horizon)\n",
    "            continue\n",
    "        if eph[i][3+ra_dec_index] == '   n.a.':\n",
    "            continue\n",
    "        jd.append(float(eph[i][0]))\n",
    "        az.append(float(eph[i][3+ra_dec_index]))\n",
    "        alt.append(float(eph[i][4+ra_dec_index]))\n",
    "        airmass.append(float(eph[i][5+ra_dec_index]))\n",
    "        ext.append(float(eph[i][6+ra_dec_index]))\n",
    "        def_ill.append(float(eph[i][7+ra_dec_index]))\n",
    "        angd.append(float(eph[i][8+ra_dec_index]))\n",
    "        obs_long.append(float(eph[i][9+ra_dec_index]))\n",
    "        obs_lat.append(float(eph[i][10+ra_dec_index]))\n",
    "        sol_long.append(float(eph[i][11+ra_dec_index]))\n",
    "        sol_lat.append(float(eph[i][12+ra_dec_index]))\n",
    "        np_ang.append(float(eph[i][13+ra_dec_index]))\n",
    "        np_dist.append(float(eph[i][14+ra_dec_index]))\n",
    "        r.append(float(eph[i][15+ra_dec_index]))\n",
    "        rdot.append(float(eph[i][16+ra_dec_index]))\n",
    "        delta_r.append(float(eph[i][17+ra_dec_index]))\n",
    "        delta_rdot.append(float(eph[i][18+ra_dec_index]))\n",
    "        lt.append(float(eph[i][19+ra_dec_index]))\n",
    "        phase_angle.append(float(eph[i][20+ra_dec_index]))\n",
    "    \n",
    "    #Interpolate between points, make a function of time for each quantity of interest:\n",
    "    if ra_dec_index == 2:\n",
    "        RA_func = interp1d(jd,RA) \n",
    "        dec_func = interp1d(jd,dec) \n",
    "    az_func = interp1d(jd,az)\n",
    "    alt_func = interp1d(jd,alt)\n",
    "    airmass_func = interp1d(jd,airmass)\n",
    "    ext_func = interp1d(jd,ext)\n",
    "    def_ill_func = interp1d(jd,def_ill)\n",
    "    angd_func = interp1d(jd,angd)\n",
    "    obs_long_func = interp1d(jd,obs_long)\n",
    "    obs_lat_func = interp1d(jd,obs_lat)\n",
    "    sol_long_func = interp1d(jd,sol_long)\n",
    "    sol_lat_func = interp1d(jd,sol_lat)\n",
    "    np_ang_func = interp1d(jd,np_ang)\n",
    "    np_dist_func = interp1d(jd,np_dist)\n",
    "    r_func = interp1d(jd,r)\n",
    "    rdot_func = interp1d(jd,rdot)\n",
    "    delta_r_func = interp1d(jd,delta_r)\n",
    "    delta_rdot_func = interp1d(jd,delta_rdot)\n",
    "    lt_func = interp1d(jd,lt)\n",
    "    phase_angle_func = interp1d(jd,phase_angle)\n",
    "    \n",
    "    #Look through a list of images\n",
    "    for i in range(0,len(image_list)):\n",
    "        im = fits.open(directory+image_list[i])\n",
    "        header = im[0].header\n",
    "        \n",
    "        if header['object'] == '            Jupiter': #!!!Maybe get rid of this? Want to append it no matter what?\n",
    "            im_jd = header['julian']\n",
    "            #print 'Appending quantities for image '+image_list[i]+' taken at '+str(im_jd)+'...'\n",
    "            \n",
    "            #Interpret each function at im_jd, the time when the Jupiter image in question was taken\n",
    "            im_az = round(az_func(im_jd),7) #Round the values, since FITS headers can't handle the big floats\n",
    "            im_alt = round(alt_func(im_jd),7)\n",
    "            im_airmass = round(airmass_func(im_jd),5)\n",
    "            im_ext = float(ext_func(im_jd))\n",
    "            im_def_ill = round(def_ill_func(im_jd),5)\n",
    "            im_angd = round(angd_func(im_jd),5)\n",
    "            im_obs_long = round(obs_long_func(im_jd),5)\n",
    "            im_obs_lat = round(obs_lat_func(im_jd),5)\n",
    "            im_sol_long = round(sol_long_func(im_jd),5)\n",
    "            im_sol_lat = round(sol_lat_func(im_jd),5)\n",
    "            im_np_ang = float(np_ang_func(im_jd))\n",
    "            im_np_dist = float(np_dist_func(im_jd))\n",
    "            im_r = round(r_func(im_jd),5)\n",
    "            im_rdot = round(rdot_func(im_jd),5)\n",
    "            im_delta_r = round(delta_r_func(im_jd),5)\n",
    "            im_delta_rdot = round(delta_rdot_func(im_jd),5)\n",
    "            im_lt = round(lt_func(im_jd),5)\n",
    "            im_phase_angle = round(phase_angle_func(im_jd),5)\n",
    "            \n",
    "            \n",
    "            #Attach them to the image header\n",
    "            header['AZI_APP'] = (im_az,'Apparent azimuth (AIRLESS) (degrees)') \n",
    "            header['ALT_APP'] = (im_alt, 'Apprent altitude (AIRLESS) (degrees)')\n",
    "            header['AIRMASS'] = im_airmass\n",
    "            header['MAG_EXT'] = (im_ext,'magnitudes') #*Paul didn't seem to use this?\n",
    "            header['ANG_DFCT'] = (im_def_ill,'Defect of illumination (arcseconds)')\n",
    "            header['ANG_DIAM'] = (im_angd,'Full planet angular diameter (arcseconds)')\n",
    "            header['SE_LON'] = (im_obs_long,'Long of targ. as seen by obs. System III (deg)')\n",
    "            header['SE_LAT'] = (im_obs_lat,'Lat of target as seen by obs. Planetodetic (deg)')\n",
    "            header['SS_LON'] = (im_sol_long,'Long of target as seen by Sun. System III (deg)')\n",
    "            header['SS_LAT'] = (im_sol_lat,'Lat of targ. as seen by Sun. Planetodetic (deg)')\n",
    "            header['NPPANGLE'] = (im_np_ang,'NP pos. ang (CCW wrt dir. of CNP) (deg)')\n",
    "            header['NPANGDIS'] = (im_np_dist,'NP ang dist from center of disk (arcsec)')\n",
    "            header['PS_NGR'] = (im_r,'Planet-Sun range (km)')\n",
    "            header['PS_RATE'] = (im_rdot,'Planet-Sun range rate (km/s)')\n",
    "            header['PE_RNG'] = (im_delta_r,'Planet-Earth range (km)')\n",
    "            header['PE_RATE'] = (im_delta_rdot,'Planet-Earth range rate (km/s)')\n",
    "            header['ONEWAYLT'] = (im_lt,'1-way light-time from Jupiter to APO (minutes)')\n",
    "            header['PHASEANG'] = (im_phase_angle,'Phase angle (degrees)')\n",
    "            \n",
    "            #Save image\n",
    "            im.writeto(directory+image_list[i],overwrite=True)\n",
    "            im.close()\n",
    "            \n",
    "#Looks through a tcc text file (From Russet) and attaches the alt and az of the instrument wrt the sky. \n",
    "\n",
    "def attach_apo(directory,images,apolog):\n",
    "    '''\n",
    "    Attaches telescope pointing data from log file from APO. Pulls the JD of the image from image_list in directory, interpolates the alt and az of the instrument at that time.\n",
    "    Email APO 3.5-m Lead Observing Specialist (Russet McMillan, mcmillan@apo.nmsu.edu, as of 2019)\n",
    "    \n",
    "    directory: directory where data is\n",
    "    images: location+name of image list\n",
    "    apolog: location and name of tel.txt files\n",
    "    '''\n",
    "    \n",
    "    image_list = np.loadtxt(images,dtype=str)\n",
    "    apo_log = np.loadtxt(apolog,dtype=str)\n",
    "    \n",
    "    #Make arrays of the log's alt, az, and JD:\n",
    "    alt = []\n",
    "    az = []\n",
    "    tcc_rot_ang = []\n",
    "    jd = []\n",
    "    \n",
    "    JD_per_s = 1./86400\n",
    "    JD_per_min = 1./1440\n",
    "    JD_per_hr = 1./24\n",
    "    \n",
    "    #Find the jd of the night; pull it from an image in the list\n",
    "    juliandate = float(int(fits.open(directory+image_list[1])[0].header['julian']))\n",
    "    \n",
    "    #make lists of alt and az from apo log to make into functions:\n",
    "    for i in range(0,len(apo_log)):\n",
    "        alt.append(float((apo_log[i][10][:-1])))\n",
    "        #Since az data is weird:\n",
    "        if 0 < float((apo_log[i][9][7:-1])) <= 180.:\n",
    "            az.append(180-float((apo_log[i][9][7:-1]))) \n",
    "        elif 180 < float((apo_log[i][9][7:-1])) <= 360.:\n",
    "            az.append(540-float((apo_log[i][9][7:-1])))\n",
    "        elif float((apo_log[i][9][7:-1])) < 0:\n",
    "            az.append(180+abs(float((apo_log[i][9][7:-1]))))\n",
    "        #from prepare_for_geocal; laking a list of tcc rotation angle.\n",
    "        #THIS ASSUMES THAT THE TELESCOPE IS RECORDING +CW until 180, then negative from ccw (Seems to be right?)\n",
    "        #append the value of ObjInsAng if it's positive\n",
    "        if float(apo_log[i][12][11:-1]) >= 0:\n",
    "            tcc_rot_ang.append(float(apo_log[i][12][11:-1]))\n",
    "        #if it's negative:\n",
    "        if float(apo_log[i][12][11:-1]) < 0:\n",
    "            tcc_rot_ang.append(360.0+float(apo_log[i][12][11:-1]))\n",
    "    \n",
    "        #Convert hours:minutes:seconds into JD, append it\n",
    "        jd.append(juliandate+0.5+(float(apo_log[i][1][0:2])*JD_per_hr)+(float(apo_log[i][1][3:5])*JD_per_min)+(float(apo_log[i][1][6:-1])*JD_per_s))\n",
    "    \n",
    "    #Make functions of alt and az as a function of JD via interp1d\n",
    "    alt_func = interp1d(jd,alt)\n",
    "    az_func = interp1d(jd,az)\n",
    "    rotang_func = interp1d(jd,tcc_rot_ang)\n",
    "    \n",
    "    #Open the image and find the JD\n",
    "    for i in range(0,len(image_list)):\n",
    "        \n",
    "        im = fits.open(directory+image_list[i])\n",
    "        header = im[0].header\n",
    "        im_jd = header['julian']\n",
    "        #print 'Appending quantities for image '+image_list[i]+' taken at '+str(im_jd)+'...'\n",
    "        \n",
    "        im_alt = round(alt_func(im_jd),6)\n",
    "        im_az = round(az_func(im_jd),6)\n",
    "        \n",
    "        #print im_jd,im_alt,im_az\n",
    "        \n",
    "        #Append the alt and az of the instrument at the image's JD\n",
    "        header['TCC_ALT'] = (im_alt,'Encoder-reported altitude from APO')\n",
    "        header['TCC_AZ'] = (im_az,'Encoder-reported azimuth from APO')\n",
    "        \n",
    "        #appending rot_ang and pnorth, stuff needed for geometric cal\n",
    "        if header['rfon'] == 1:\n",
    "            im_jd = header['julian']\n",
    "            #print 'Appending telescope quantities for image '+image_list[i]+' taken at '+str(im_jd)+'...'\n",
    "\n",
    "            im_rotang = round(rotang_func(im_jd),5)\n",
    "\n",
    "            #Append the alt and az of the instrument at the image's JD\n",
    "            header['ROT_ANG'] = (im_rotang,'(Degrees) angle cw from pos vertical to NCP')\n",
    "\n",
    "            #Find np_ang\n",
    "            npa = round(im_rotang + header['NPPANGLE'],5)\n",
    "            header['PNORTH'] = (npa,'Angle of the planets NP cw from CN (Degrees)')\n",
    "        \n",
    "        #Save image:\n",
    "        im.writeto(directory+image_list[i],overwrite=True)\n",
    "        im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Program to make a hot pixel mask if one hasn't been made yet\n",
    "def pix_mask_maker(flatlist, directory,pixmask_path_and_name):\n",
    "    \n",
    "    '''\n",
    "    Makes a hot pixel mask from list of flats. If the same pixel is 5 sigma above the average of its neighbors in over half of the flats, flagged as a hot pixel and saved to the pixel mask.\n",
    "    \n",
    "    flatlist: path+name of list of flats\n",
    "    directory: path of location of flats\n",
    "    pixmask_path_and_name: path+name of where the pixel mask wil be saved.\n",
    "    Completed pixel masks, on desktop, are currently in ~/NAIC/pixel_masks/\n",
    "    '''\n",
    "    \n",
    "    image_list = np.loadtxt(flatlist,dtype=str)\n",
    "    hot_pix_list = [] # Big list of all potential 'hot pixels' detected in each image\n",
    "\n",
    "    # Define the empty pixel mask:\n",
    "    im = fits.open(directory+image_list[1])\n",
    "    dimension1 = im[0].header['NAXIS1']\n",
    "    dimension2 = im[0].header['NAXIS2']\n",
    "    pix_mask = np.zeros((dimension1,dimension2)) #Empty pixel mask\n",
    "    im.close()\n",
    "    \n",
    "    # Function to apply to neighbors:\n",
    "    def neighbors(values):\n",
    "        # Returns mean of neighbors plus 5 std of neighbors for given pixel value\n",
    "        return np.mean(values)+5*np.std(values)\n",
    "\n",
    "    # Loop through flats, finding potential hot pixels:\n",
    "    for i in range(0,len(image_list)):\n",
    "        im = fits.open(directory+image_list[i])\n",
    "\n",
    "        # neighbor footprint\n",
    "        footprint = np.array([[1,1,1],\n",
    "                              [1,0,1],\n",
    "                              [1,1,1]])\n",
    "\n",
    "        # make array of median + 5 std devs of neighbors:\n",
    "        neighbor_results = ndimage.generic_filter(im[0].data, neighbors, footprint=footprint)\n",
    "        g,h = np.where(im[0].data > neighbor_results) # positions of hot pixels\n",
    "        \n",
    "        # add that image's hot pixels to master list\n",
    "        for l in range(0,len(g)):\n",
    "            hot_pix_list.append((g[l],h[l]))\n",
    "            \n",
    "        # print out percentage complete\n",
    "        if i%3 == 0:\n",
    "            print round(float(i)/len(image_list),4)*100,'% done;',i,'images analyzed'\n",
    "            \n",
    "    # Make the pixel mask:\n",
    "    d = {x:hot_pix_list.count(x) for x in hot_pix_list} # in hot_pix_list, count the times each pair shows up\n",
    "    pairs = d.keys() #unique x and y coordinates of each hot pixel\n",
    "    number_of_pairs = d.values() #number of times each x and y coordinate is counted as a hot pixel\n",
    "    number_of_flats = len(image_list)\n",
    "\n",
    "    #If the hot pixel shows up in more than half the flats, save position as official hot pixel in the pixel mask\n",
    "    for i in range(0,len(number_of_pairs)):\n",
    "        if number_of_pairs[i] >= number_of_flats/2.: \n",
    "            pix_mask[pairs[i][0]][pairs[i][1]] = 1\n",
    "\n",
    "    # Save the pixel mask file\n",
    "    np.savetxt(pixmask_path_and_name,pix_mask,fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to correct hot pixels using pixel mask and CR correct \n",
    "\n",
    "def pixel_corrector(directory,imagelist,pixelmask,rfon_or_off):\n",
    "    '''\n",
    "    Program to correct for cosmic rays and hot pixels. \n",
    "    Uses http://ccdproc.readthedocs.io/en/latest/api/ccdproc.cosmicray_lacosmic.html#ccdproc.cosmicray_lacosmic to correct for cosmic rays\n",
    "    '''\n",
    "    \n",
    "    images = np.loadtxt(imagelist,dtype=str)\n",
    "    pixel_mask = np.loadtxt(pixelmask,dtype=int)\n",
    "    \n",
    "    # Function to apply to neighbors:\n",
    "    def neighbors(values):\n",
    "        # Returns median of neighbors\n",
    "        return np.median(values)\n",
    "\n",
    "    # neighbor footprint\n",
    "    footprint = np.array([[1,1,1],\n",
    "                          [1,0,1],\n",
    "                          [1,1,1]])\n",
    "    \n",
    "    for i in range(0,len(images)):\n",
    "        im = fits.open(directory+images[i])\n",
    "        if im[0].header['rfon'] == rfon_or_off:\n",
    "            \n",
    "            # Replace pixels where pix_mask is non-zero with median of neighbors:\n",
    "            # array of each pixels' median of its neighbors, same size as image:\n",
    "            median_array = ndimage.generic_filter(im[0].data, neighbors, footprint=footprint)\n",
    "            # Set hot pixel locations in image array to their neighbors' median value:\n",
    "            im[0].data[np.where(pixel_mask > 0)] = median_array[np.where(pixel_mask > 0)]\n",
    "            \n",
    "            # Add the locations of cosmic rays as a 2nd HDU before data array gets changed (acess via im[1].data, will be integers)\n",
    "            im.append(fits.ImageHDU(data = ccdproc.cosmicray_lacosmic(im[0].data,sigclip=7)[1].astype(int),name='CR_MASK'))\n",
    "            \n",
    "            #Fix the image, save it to the data array\n",
    "            im[0].data = ccdproc.cosmicray_lacosmic(im[0].data,sigclip=7)[0]\n",
    "\n",
    "            #Write history statement, save and close FITS file\n",
    "            im[0].header['history'] = 'Hot pixels and cosmic rays corrected at '+str(datetime.datetime.now())\n",
    "            im.writeto(directory+images[i],overwrite=True)\n",
    "        im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Program to subtract RF-off images. \n",
    "# This version only looks for closeness in time, no pointing requirements. Probably fine, since we're already looking for closeness in time. \n",
    "\n",
    "def rf_off(directory,imlist):\n",
    "    '''\n",
    "    Subtracts rf-off Jupiter images from rf-on Jupiter images depending on closeness in time.\n",
    "    \n",
    "    Looks for closeness in time (if longer than 600 sec = not usable RF-off).\n",
    "    Assumes the list you feed it has already been reduced to a single object, or is single image cube.\n",
    "    Added header keyword indicating rf-off subtraction has been performed or not, along with history statement. \n",
    "    '''\n",
    "    \n",
    "    del_t_max = 0.00694444444 #max difference in JD for an rf-off to be usable (600 s, from Paul's thesis)\n",
    "    image_file = np.loadtxt(imlist,dtype=str) #load the list of images\n",
    "    \n",
    "    for i in range(0,len(image_file)):\n",
    "        im = fits.open(directory+image_file[i])\n",
    "        if im[0].header['rfon'] == 1: #subtract image only if it's rf-on\n",
    "            \n",
    "            im[0].data = np.array(im[0].data,dtype=float) #load the image array. Save as floats to avoid issues with -numbers, floats\n",
    "\n",
    "            rfon_exp = im[0].header['exposure']\n",
    "            \n",
    "            rfoff_list = [] # empty list to populate with nearby rf-off images\n",
    "            \n",
    "            for j in range(1,20): # look at 20 images on either side of image in question\n",
    "                if i-j > 0: #Accounts for rf-on images at the beginning or end of \n",
    "                    #If it's an RF-off image:\n",
    "                    if fits.open(directory+image_file[i-j])[0].header['rfon'] == 0:\n",
    "                        #If exp time is the same as the rf-on image\n",
    "                        if fits.open(directory+image_file[i-j])[0].header['exposure'] == rfon_exp:\n",
    "                            rfoff_list.append(image_file[i-j])\n",
    "                if i+j < len(image_file): \n",
    "                    if fits.open(directory+image_file[i+j])[0].header['rfon'] == 0:\n",
    "                        #If exp time is the same as the rf-on image\n",
    "                        if fits.open(directory+image_file[i+j])[0].header['exposure'] == rfon_exp:\n",
    "                            rfoff_list.append(image_file[i+j])\n",
    "                                                                                                \n",
    "            #CHECKING TIME\n",
    "                        \n",
    "            #Setting up julian dates to use when finding the differences between them:\n",
    "            jd_rfon = [] #making a list, because Python is rounding JD when try to save it directly to a variable\n",
    "            jd_rfon.append(im[0].header['julian']) #The JD of the rf-on image\n",
    "            jd_rfoff = [] #A list of the JDs of the rf-off images\n",
    "            for k in range(0,len(rfoff_list)):\n",
    "                jd_rfoff.append(fits.open(directory+rfoff_list[k])[0].header['julian'])\n",
    "            #Make a list of the difference between the rf-on JD and rf-off JD's. \n",
    "            jd_diff = []\n",
    "            for l in range(0,len(rfoff_list)):\n",
    "                jd_diff.append(abs(jd_rfoff[l]-jd_rfon[0]))            \n",
    "            \n",
    "            #Choose the closest and 2nd closest RF-offs as the primary RF-off and secondary RF-off, respectively\n",
    "            if len(jd_diff) >= 2:\n",
    "                primary_del_t = min(jd_diff) #find the smallest value. that's the closest rf-off in JD\n",
    "                jd_diff.remove(primary_del_t) #take out the smallest value\n",
    "                secondary_del_t = min(jd_diff) #find the new smallest value\n",
    "            elif len(jd_diff) == 1:\n",
    "                primary_del_t = min(jd_diff)\n",
    "                secondary_del_t = 20.0 # need to assign a value here or else will break later.\n",
    "                print 'Only one RF-off image found.'\n",
    "            elif len(jd_diff) == 0:\n",
    "                print 'No nearby images found with the same exposure length. No usable RF-off image for', image_file[i]\n",
    "                continue\n",
    "\n",
    "            \n",
    "            #Check that the closest image isn't farther than 600 s\n",
    "            if primary_del_t > del_t_max:\n",
    "                print 'Primary RF-off image is farther than the allowed del_t. No usable RF-off image for', image_file[i]\n",
    "                continue #look at next RF-on image\n",
    "\n",
    "            #Doing some janky stuff to find the RF-off image that corresponds to 'primary_del_t' and 'secondary_del_t'\n",
    "            for m in range(0,len(rfoff_list)): # loop through list of rf-off images\n",
    "                jdrfoff = fits.open(directory+rfoff_list[m])[0].header['julian'] #find the jd for that image\n",
    "                if abs(jd_rfon[0]-jdrfoff) == primary_del_t: #find the jd for the rf off and rf on. if it matches, it's the primary image\n",
    "                    primary_rfoff_image = rfoff_list[m] #The name of the RF-off image closest in time to the RF-on image\n",
    "                elif abs(jd_rfon[0]-jdrfoff) == secondary_del_t:\n",
    "                    secondary_rfoff_image = rfoff_list[m] #The name of the RF-off image 2nd closest in time to the RF-on image\n",
    "            \n",
    "            #print 'primary and secondary rf-off images',primary_rfoff_image,secondary_rfoff_image\n",
    "            \n",
    "                        \n",
    "            if abs(primary_del_t-secondary_del_t)/primary_del_t < 0.1 and secondary_del_t <= del_t_max:\n",
    "                #and abs(rfon_distance_check-primary_distance_check) <= 0.001 and abs(rfon_distance_check-secondary_distance_check) <= 0.001:\n",
    "                #old pointing requirements\n",
    "                #and pri_rfon_alt_diff <= 0.002 and pri_rfon_az_diff <= 0.002 and sec_rfon_alt_diff <= 0.002 and sec_rfon_az_diff <= 0.002:\n",
    "                print 'The primary and secondary rf-off images are close enough in time and pointing to be averaged for image', image_file[i]\n",
    "                #Make average rf-off image, using primary and secondary rf-off images:\n",
    "                rfoff_ave = (fits.open(directory+primary_rfoff_image)[0].data + fits.open(directory+secondary_rfoff_image)[0].data)/2.\n",
    "                #Subtract averaged rf-off:\n",
    "                im[0].data -= rfoff_ave\n",
    "                #Save header history\n",
    "                im[0].header['history'] = 'Subtracted average of primary and secondary RF-off images, '+primary_rfoff_image+' & '+secondary_rfoff_image+', on '+str(datetime.datetime.now())\n",
    "                im[0].header['RFSUB'] = (1,'RF-off sub completed? 1 = yes 0 = no')\n",
    "                im[0].writeto(directory+image_file[i],overwrite=True)\n",
    "                im.close()\n",
    "                \n",
    "            elif primary_del_t <= del_t_max:\n",
    "                #and abs(rfon_distance_check-primary_distance_check) <= 0.001:\n",
    "                #old pointing requirements\n",
    "                #and pri_rfon_alt_diff <= 0.002 and pri_rfon_az_diff <= 0.002:\n",
    "                #print 'Only the primary RF-off image is close enough in time and pointing to be subtracted for image',image_file[i]\n",
    "                im[0].data -= fits.open(directory+primary_rfoff_image)[0].data\n",
    "                im[0].header['history'] = 'Subtracted primary RF-off, '+primary_rfoff_image+', on '+str(datetime.datetime.now())\n",
    "                im[0].header['RFSUB'] = (1,'RF-off sub completed? 1 = yes 0 = no')\n",
    "                im[0].writeto(directory+image_file[i],overwrite=True)\n",
    "                im.close()\n",
    "                \n",
    "            elif secondary_del_t <= del_t_max:\n",
    "                #and abs(rfon_distance_check-secondary_distance_check) <= 0.001:\n",
    "                #old pointing requirements\n",
    "                #and sec_rfon_alt_diff <= 0.002 and sec_rfon_az_diff <= 0.002:\n",
    "                #print 'Only the secondary RF-off image is close enough in time to be subtracted for image',image_file[i]                    \n",
    "                im[0].data -= fits.open(directory+secondary_rfoff_image)[0].data\n",
    "                im[0].header['history'] = 'Subtracted secondary RF-off, '+secondary_rfoff_image+', on '+str(datetime.datetime.now())\n",
    "                im[0].header['RFSUB'] = (1,'RF-off sub completed? 1 = yes 0 = no')\n",
    "                im[0].writeto(directory+image_file[i],overwrite=True)\n",
    "                im.close()\n",
    "                \n",
    "            else:\n",
    "                print 'None of the RF-off images are close enough. No subtraction performed on',image_file[i]\n",
    "                im[0].header['RFSUB'] = (0,'RF-off sub completed? 1 = yes 0 = no')\n",
    "                im[0].writeto(directory+image_file[i],overwrite=True)\n",
    "                im.close()\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def div_by_exptime(directory,list_of_images):\n",
    "    '''\n",
    "    Divides images by exposure time. Only divides RF-on images, so be sure to do this step after RF-off subtractin has been completed.\n",
    "    '''\n",
    "    imlist = np.loadtxt(list_of_images,dtype=str)\n",
    "    for i in range(0,len(imlist)):\n",
    "        im = fits.open(directory+imlist[i])\n",
    "        if im[0].header['rfon'] == 1:\n",
    "            exptime = im[0].header['exposure']\n",
    "            im[0].data = np.array(im[0].data,dtype=float)\n",
    "            im[0].data /= exptime\n",
    "            im[0].header['HISTORY'] = 'Image divided by exposure time.'\n",
    "            im.writeto(directory+imlist[i],overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flat_div(data_directory,imlist,flat_directory,flatlist):\n",
    "    '''\n",
    "    Divides RF-on images by flats with corresponding wavelength. \n",
    "    '''\n",
    "    image_list = np.loadtxt(imlist,dtype=str)\n",
    "    flat_list = np.loadtxt(flatlist,dtype=str)\n",
    "    \n",
    "    for i in range(0,len(image_list)):\n",
    "        \n",
    "        im = fits.open(data_directory+image_list[i])\n",
    "        im_image = im[0].data\n",
    "        im_header = im[0].header\n",
    "        \n",
    "        if im[0].header['rfon'] == 1: \n",
    "            im_wavelength = im[0].header['lambda']\n",
    "            \n",
    "            check_if_already_divided = []\n",
    "            #Find the flat with the correct wavelength:\n",
    "            for j in range(0,len(flat_list)):\n",
    "                \n",
    "                flat = fits.open(flat_directory+flat_list[j])\n",
    "                flat_image = flat[0].data\n",
    "                flat_header = flat[0].header\n",
    "                flat_wavelength = flat_header['lambda']\n",
    "                \n",
    "                if flat_wavelength == im_wavelength and len(check_if_already_divided) == 0 and flat_header['rfon'] == 1:\n",
    "                    \n",
    "                    #Divide by flat\n",
    "                    im[0].data = np.array(im[0].data,dtype=float)\n",
    "                    im[0].data = np.array(im[0].data)/flat_image\n",
    "\n",
    "                    im[0].header['history'] = 'Image divided by '+flat_directory+flat_list[j]+' on '+str(datetime.datetime.now())\n",
    "                    im.writeto(data_directory+image_list[i],overwrite=True) #Save over the old image\n",
    "                    \n",
    "                    check_if_already_divided.append(1)\n",
    "                    \n",
    "                else:\n",
    "                    continue\n",
    "        im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flat_div_single_image(data_directory,image,flat_directory,flatlist):\n",
    "    '''\n",
    "    Same as flat_div() but for a single frame (can be used as check)\n",
    "    '''\n",
    "    flat_list = np.loadtxt(flatlist,dtype=str)\n",
    "            \n",
    "    im = fits.open(data_directory+image)\n",
    "    im_image = im[0].data\n",
    "    im_header = im[0].header\n",
    "\n",
    "    if im[0].header['rfon'] == 1: \n",
    "        im_wavelength = im[0].header['lambda']\n",
    "\n",
    "        check_if_already_divided = []\n",
    "        #Find the flat with the correct wavelength:\n",
    "        for j in range(0,len(flat_list)):\n",
    "\n",
    "            flat = fits.open(flat_directory+flat_list[j])\n",
    "            flat_image = flat[0].data\n",
    "            flat_header = flat[0].header\n",
    "            flat_wavelength = flat_header['lambda']\n",
    "\n",
    "            if flat_wavelength == im_wavelength and len(check_if_already_divided) == 0 and flat_header['rfon'] == 1:\n",
    "\n",
    "                #Divide by flat\n",
    "                im[0].data = np.array(im[0].data,dtype=float)\n",
    "                im[0].data = im[0].data/flat_image\n",
    "\n",
    "                im[0].header['history'] = 'Image divided by '+flat_directory+flat_list[j]+' on '+str(datetime.datetime.now())\n",
    "                im.writeto(data_directory+image,overwrite=True) #Save over the old image\n",
    "\n",
    "                check_if_already_divided.append(1)\n",
    "                print 'Divided.'\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "        im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fringe_fix(directory_data,imagelist_data,directory_fringe,imagelist_fringe):\n",
    "    '''\n",
    "    Directory - path of location of images\n",
    "    Imagelist - path+name of text file of image list\n",
    "    Assumes the fringe images are fits files with their corresponding wavelength in the header. Divides data by the fringing image.\n",
    "    Be careful to make sure the wavelengths are the same!!\n",
    "    '''\n",
    "    imlist_data = np.loadtxt(imagelist_data,dtype=str)\n",
    "    imlist_fringe = np.loadtxt(imagelist_fringe,dtype=str)\n",
    "\n",
    "    for i in range(0,len(imlist_data)):\n",
    "        im_data = fits.open(directory_data+imlist_data[i])\n",
    "        if im_data[0].header['rfon'] == 1:\n",
    "            # Find the matching fringe image\n",
    "            for j in range(0,len(imlist_fringe)):\n",
    "                im_fringe = fits.open(directory_fringe+imlist_fringe[j])\n",
    "                if round(im_fringe[0].header['lambda'],3) == im_data[0].header['lambda']: # assuming the wavelength is in the header\n",
    "                    # If wavelengths match, divide data image by fringing image\n",
    "                    print 'Fixing fringing for wavelength ',im_data[0].header['lambda']\n",
    "                    div = np.array(im_data[0].data)/np.array(im_fringe[0].data)\n",
    "                    im_data[0].data = div\n",
    "                    # Add keyword saying its been divided already\n",
    "                    im_data[0].header['history'] = 'Fringing has been corrected'\n",
    "                    # Save image\n",
    "                    im_data.writeto(directory_data+imlist_data[i],overwrite=True) \n",
    "                    \n",
    "                im_fringe.close()\n",
    "                \n",
    "        im_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_filt(directory,imagelist):\n",
    "    '''\n",
    "    Gaussian Filter replacement for noisy flats. Makes low- and high-pass filters, and if flat is too noisy, replaces it with low-pass filter.\n",
    "    Save noisy flats as their low-pass filter (based on 0.04 sigma cutoff that Paul used)\n",
    "    '''\n",
    "    imlist = np.loadtxt(imagelist,dtype=str)\n",
    "    \n",
    "    # Get rid of negative values in flats\n",
    "    for i in range(0,len(imlist)):\n",
    "        im = fits.open(directory+imlist[i])\n",
    "        im[0].data = abs(im[0].data)\n",
    "        im.writeto(directory+imlist[i],overwrite=True)\n",
    "        im.close()\n",
    "    \n",
    "    # Calculate the std dev of a 30 pixel FWHM (Paul used 30 pixels)\n",
    "    FWHM = 30\n",
    "    stdev = FWHM/2.355 # from gaussian formula\n",
    "\n",
    "    for i in range(0,len(imlist)-130): # Ignore longer wavelength images. Applying a gaussian filter to those will be bad.\n",
    "        im = fits.open(directory+imlist[i])\n",
    "        if im[0].header['rfon'] == 1:\n",
    "\n",
    "            # Make low-pass filter:\n",
    "            low_pass = filters.gaussian_filter(im[0].data,stdev)\n",
    "\n",
    "            # Make high-pass filter:\n",
    "            high_pass = im[0].data - filters.gaussian_filter(im[0].data,stdev)\n",
    "\n",
    "            # Define noise in high-pass filter:\n",
    "            #std.append(np.std(im[0].data-filters.gaussian_filter(im[0].data,stdev))/np.median(im[0].data))\n",
    "            #wl.append(im[0].header['lambda'])\n",
    "\n",
    "            if np.std(high_pass)/np.median(im[0].data) > 0.04: # Normalize std by median value\n",
    "                im[0].data = low_pass\n",
    "                im[0].header['history'] = 'Flat replaced by gaussian low pass filter'\n",
    "                im.writeto(directory+imlist[i],overwrite=True)\n",
    "                im.close()\n",
    "            else:\n",
    "                im.close()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilations of programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flat_prep(flatlist,flatdirectory):\n",
    "    \n",
    "    '''\n",
    "    Prepares flat cube for use with Jupiter/cal star images. Order of inquiries aren't necessarily the order they're ran in.\n",
    "    '''\n",
    "    \n",
    "    wl_correction_query = raw_input('Is this dataset from before January 2018? (if y, will corect wavelength)? y or n')\n",
    "    ds_corr_query = raw_input('Do you want to correct for the Doppler shift resulting from the moition of the planet? y or n ')\n",
    "    \n",
    "    pix_correct_query = raw_input('Do you want to correct for hot pixels and cosmic rays? y or n ')\n",
    "    if pix_correct_query == 'y':\n",
    "        hot_pixel_mask_query = raw_input('Does this dataset have a hot pixel mask made already (if y will correct for hot/bad pixels, if n will make new one based on flat list and then correct for hot/bad pixels)? y or n')\n",
    "        if hot_pixel_mask_query == 'y':\n",
    "            pixelmaskname = raw_input('What is the path+name of the pixel mask?')\n",
    "        else:\n",
    "            pixelmaskname = raw_input('What do you want the path+name of the pixel mask to be?')\n",
    "\n",
    "    fringe_query = raw_input('Correct for fringing? y or n')\n",
    "    if fringe_query == 'y':\n",
    "        fringedirectory = raw_input('What is the path of the location of fringing frames?')\n",
    "        fringeimagelist = raw_input('What is the path+name of the list of fringing frames? ')\n",
    "    \n",
    "    rfoff_query_flat = raw_input('Would you like to RF-off subtract flats? y or n ')\n",
    "    exptime_divide_query = raw_input('Do you want to divide by exposure time? y or n ')\n",
    "    gaussian_filter_query = raw_input('Would you like to replace low-SNR flats with a Gaussian filter? y or n')\n",
    "    \n",
    "    \n",
    "    print ' '\n",
    "    print 'RUNNING PIPELINE . . . '\n",
    "    print ' '\n",
    "\n",
    "    \n",
    "    # Step 1: Wavelength Correction\n",
    "    if wl_correction_query == 'y':\n",
    "        print 'Correcting wavelength...'\n",
    "        #If wavelength needs to be corrected since it was taken before Jan. 2018\n",
    "        #correct flats\n",
    "        wavelength_corrector(flatlist,flatdirectory)\n",
    "    elif wl_correction_query == 'n':\n",
    "        print 'Not correcting wavelength.'\n",
    "    \n",
    "    if ds_corr_query == 'y':\n",
    "        print 'Correcting wavelength for Doppler shift...'\n",
    "        doppler_shift_corr(sciencelist,sciencedirectory)\n",
    "    else:\n",
    "        print 'Not correcting for Doppler shift.'\n",
    "    \n",
    "    \n",
    "    # Step 2: make pixel mask, or not\n",
    "    if pix_correct_query == 'y':\n",
    "        if hot_pixel_mask_query == 'y':\n",
    "            print 'Using '+str(pixelmaskname)\n",
    "        else:\n",
    "            #If need to make pixel mask, make it from flat list\n",
    "            print 'Making pixel mask...'\n",
    "            pix_mask_maker(flatlist, flatdirectory,pixelmaskname)\n",
    "            \n",
    "    # Step 3: Hot pixel correction in rf-off images\n",
    "        print 'Correcting pixels and cosmic rays in RF-off images...'\n",
    "        #Once hot pixel mask exists and has been saved to pixelmaskname, use it to correct for hot pixels AND correct for cosmic rays for rf-off images:\n",
    "        pixel_corrector(flatdirectory,flatlist,pixelmaskname,0) #flats\n",
    "        \n",
    "    else:\n",
    "        print 'Not correcting hot pixels or cosmic rays in RF-off images.'\n",
    "    \n",
    "    \n",
    "    # Step 4: Subtract RF-off images\n",
    "    if rfoff_query_flat == 'y':\n",
    "        print 'RF-off subtracting flats...'\n",
    "        # Next, flats \n",
    "        rf_off(flatdirectory,flatlist)\n",
    "    else:\n",
    "        print 'Not RF-off subtracting flats.'\n",
    "    \n",
    "    # Step 5: correct rf-on images\n",
    "    if pix_correct_query == 'y':\n",
    "        print 'Correcting pixels and cosmic rays in RF-on flats...'\n",
    "        pixel_corrector(flatdirectory,flatlist,pixelmaskname,1) #flats\n",
    "    else:\n",
    "        print 'Not correcting pixels or cosmic rays in RF-on images.'\n",
    "    \n",
    "    # Step 6: Divide by exposure time\n",
    "    if exptime_divide_query == 'y':\n",
    "        # Flats:\n",
    "        print 'Dividing flats by exposure time...'\n",
    "        div_by_exptime(flatdirectory,flatlist)\n",
    "    \n",
    "    # Step 7: Correct for fringing\n",
    "    if fringe_query == 'y':\n",
    "        print 'Correcting for fringing.'\n",
    "        fringe_fix(flatdirectory,flatlist,fringedirectory,fringeimagelist)\n",
    "    else:\n",
    "        print 'Not correcting for fringing.'\n",
    "    \n",
    "    # Step 8: Apply Gaussian filter\n",
    "    if gaussian_filter_query == 'y':\n",
    "        print 'Replacing low-SNR filters with Gaussian filter.'\n",
    "        # Fix with filters:\n",
    "        gaussian_filt(flatdirectory,flatlist)\n",
    "    else:\n",
    "        print 'Not replacing low-SNR flats with filter.'\n",
    "    \n",
    "    \n",
    "    \n",
    "    print 'Flat prep complete.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example input:\n",
    "flat_prep('/Volumes/external_hd/march2017/flatlist','/Volumes/external_hd/march_2017_newfringeframes/flats/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_datacube(sciencelist,sciencedirectory,flatlist,flatdirectory,eph_file,apo_log):\n",
    "    \n",
    "    '''\n",
    "    #Calling all programs to reduce science data (not specific to Jupiter)\n",
    "\n",
    "    # ONLY CORRECTS SCIENCE IMAGES, NOT FLATS. \n",
    "    # CORRECT FLATS FIRST WITH flat_prep()\n",
    "\n",
    "    #Format of variables:\n",
    "    #sciencelist = '/directory/path/nameoflist'\n",
    "    #sciencedirectory = '/directory/path/'\n",
    "    #flatlist = '/directory/path/nameoflist'\n",
    "    #flatdirectory = '/directory/path/'\n",
    "    #eph_file = '/directory/path/name_of_ephemeris_file'\n",
    "    #apo_log = '/directory/path/name_of_tcc_file'\n",
    "\n",
    "    #Before using this program:\n",
    "    #-Finalize science image list. This means check for saturation, repeats, aberrations before running this program.\n",
    "    #-Double check TCC files. Do they have the correct number of columns?\n",
    "    #-Double check eph files. Do they include RA/dec or not?\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    print 'MAKE SURE FLATS HAVE ALREADY BEEN PREPARED.'\n",
    "    \n",
    "    \n",
    "    wl_correction_query = raw_input('Is this dataset from before January 2018? (if y, will corect wavelength) y or n')\n",
    "    ds_corr_query = raw_input('Do you want to correct for the Doppler shift resulting from the moition of the planet? y or n (Keep in mind wavelength of fringing images)')\n",
    "    \n",
    "    eph_attach_query = raw_input('Would you like to attach ephemerides and pointing info? y or n ')\n",
    "    \n",
    "    pix_correct_query = raw_input('Do you want to correct for hot pixels and cosmic rays? y or n ')\n",
    "    if pix_correct_query == 'y':\n",
    "        hot_pixel_mask_query = raw_input('Does this dataset have a hot pixel mask made already (if y will correct for hot/bad pixels, if n will make new one based on flat list and then correct for hot/bad pixels)? y or n')\n",
    "        if hot_pixel_mask_query == 'y':\n",
    "            pixelmaskname = raw_input('What is the path+name of the pixel mask?')\n",
    "        else:\n",
    "            pixelmaskname = raw_input('What do you want the path+name of the pixel mask to be?')\n",
    "    \n",
    "    rfoff_query = raw_input('Would you like to RF-off subtract science images? y or n ')\n",
    "    \n",
    "    exptime_divide_query = raw_input('Do you want to divide SCIENCE IMAGES by exposure time? y or n ')\n",
    "    \n",
    "    fringe_query = raw_input('Correct for fringing? y or n')\n",
    "    if fringe_query == 'y':\n",
    "        fringedirectory = raw_input('What is the path of the location of fringing frames?')\n",
    "        fringeimagelist = raw_input('What is the path+name of the list of fringing frames? ')\n",
    "    \n",
    "    flat_query = raw_input('Do you want to divide by flats? y or n ')\n",
    "\n",
    "    print ' '\n",
    "    print 'RUNNING PIPELINE . . . '\n",
    "    print ' '\n",
    "    \n",
    "    #STEP 1: Correct wavelength (or not)\n",
    "    \n",
    "    if wl_correction_query == 'y':\n",
    "        print 'Correcting wavelength...'\n",
    "        #If wavelength needs to be corrected since it was taken before \n",
    "        #correct science images\n",
    "        wavelength_corrector(sciencelist,sciencedirectory)\n",
    "    elif wl_correction_query == 'n':\n",
    "        print 'Not correcting wavelength.'\n",
    "        \n",
    "    if ds_corr_query == 'y':\n",
    "        print 'Correcting wavelength for Doppler shift...'\n",
    "        doppler_shift_corr(sciencelist,sciencedirectory)\n",
    "    else:\n",
    "        print 'Not correcting for Doppler shift.'\n",
    "        \n",
    "        \n",
    "    # STEP 2: Attach ephemerides\n",
    "    \n",
    "    if eph_attach_query == 'y':\n",
    "        print 'Attaching ephimerides...'\n",
    "        attach_eph(sciencedirectory,sciencelist,eph_file)\n",
    "        print 'Attaching APO pointing data...'\n",
    "        attach_apo(sciencedirectory,sciencelist,apo_log)\n",
    "    else:\n",
    "        print 'Not attaching ephemerides and pointing info.'\n",
    "    \n",
    "    \n",
    "    # STEP 3: Make hot pixel mask (if need to) and/or correct for hot pixels in rf-off images\n",
    "    \n",
    "    # make pixel mask, or not\n",
    "    if pix_correct_query == 'y':\n",
    "        if hot_pixel_mask_query == 'y':\n",
    "            print 'Using '+str(pixelmaskname)\n",
    "        else:\n",
    "            #If need to make pixel mask, make it from flat list\n",
    "            print 'Making pixel mask...'\n",
    "            pix_mask_maker(sciencelist, sciencedirectory,pixelmaskname)\n",
    "            \n",
    "    # Hot pixel correction in rf-off images\n",
    "        print 'Correcting pixels and cosmic rays in RF-off images...'\n",
    "        #Once hot pixel mask exists and has been saved to pixelmaskname, use it to correct for hot pixels AND correct for cosmic rays for rf-off images:\n",
    "        pixel_corrector(sciencedirectory,sciencelist,pixelmaskname,0) #flats\n",
    "        \n",
    "    else:\n",
    "        print 'Not correcting hot pixels or cosmic rays in RF-off images.'\n",
    "    \n",
    "    \n",
    "    # STEP 4: Once rf-off images are prepared, subtract them from rf-on images\n",
    "    if rfoff_query == 'y':\n",
    "        print 'RF-off subtracting science images...'\n",
    "        # First, science images\n",
    "        rf_off(sciencedirectory,sciencelist)\n",
    "    else:\n",
    "        print 'Not RF-off subtracting science images.'\n",
    "    \n",
    "    \n",
    "    # STEP 5: Correct subtracted RF-on images for cosmic rays and hot pixels\n",
    "    if pix_correct_query == 'y':\n",
    "        print 'Correcting pixels and cosmic rays in RF-on images...'\n",
    "        pixel_corrector(sciencedirectory,sciencelist,pixelmaskname,1) #science images\n",
    "    else:\n",
    "        print 'Not correcting pixels or cosmic rays in RF-on images.'\n",
    "    \n",
    "    \n",
    "    # STEP 6: Divide science images by exposure time (to prep for flat division)\n",
    "    if exptime_divide_query == 'y':\n",
    "        print 'Dividing science images by exposure time...'\n",
    "        div_by_exptime(sciencedirectory,sciencelist)\n",
    "    \n",
    "    # STEP 7: Correct for fringing\n",
    "    if fringe_query == 'y':\n",
    "        print 'Correcting for fringing.'\n",
    "        fringe_fix(sciencedirectory,sciencelist,fringedirectory,fringeimagelist)\n",
    "    else:\n",
    "        print 'Not correcting for fringing.'\n",
    "    \n",
    "    # STEP 8: Flat divide\n",
    "    if flat_query == 'y':\n",
    "        print 'Flat dividing...'\n",
    "        # Note: This flat division program does not use any fringe correction. Just matches flats by wavelength. \n",
    "        flat_div(sciencedirectory,sciencelist,flatdirectory,flatlist)\n",
    "    else:\n",
    "        print 'Not dividing by flats.'\n",
    "    \n",
    "    print 'Pipeline complete! Images have been eph-attached, RF-off subbed, exp time divided, flat divided.'\n",
    "    \n",
    "    print 'Be sure to manually look through images to make sure they look okay, that there\\'s no faulty RF-off subtraction, etc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input example:\n",
    "reduce_datacube('/Users/dahlek/Desktop/may2019/imlist','/Users/dahlek/Desktop/may2019/','/Volumes/external_hd//march2017/flatlist','/Volumes/external_hd/march2017/redo/flats/','/Users/dahlek/Desktop/march2017/eph_march2017','/Users/dahlek/Desktop/march2017/170327_tel.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''CAL STAR VERSION'''\n",
    "#sciencelist = path+name of calstar cube\n",
    "#sciencedirectory = path of calstar data location\n",
    "# this version doesn't query you at the beginning, so have to wait for queries as pipeline progresses\n",
    "\n",
    "def reduce_datacube_calstar(sciencelist,sciencedirectory,flatlist,flatdirectory):\n",
    "    \n",
    "    #STEP 1: Correct wavelength (or not)\n",
    "    \n",
    "    wl_correction_query = raw_input('Is this dataset from before January 2018? (if y, will corect wavelength) y or n')\n",
    "    ds_corr_query = raw_input('Do you want to correct for the Doppler shift resulting from the moition of the planet? y or n ')\n",
    "    \n",
    "    if wl_correction_query == 'y':\n",
    "        print 'Correcting wavelength...'\n",
    "        #If wavelength needs to be corrected since it was taken before \n",
    "        #correct science images\n",
    "        wavelength_corrector(sciencelist,sciencedirectory)\n",
    "    elif wl_correction_query == 'n':\n",
    "        print 'Not correcting wavelength.'\n",
    "        \n",
    "    if ds_corr_query == 'y':\n",
    "        print 'Correcting wavelength for Doppler shift...'\n",
    "        doppler_shift_corr(sciencelist,sciencedirectory)\n",
    "    else:\n",
    "        print 'Not correcting for Doppler shift.'\n",
    "        \n",
    "        \n",
    "    # STEP 2: Attach ephemerides\n",
    "    \n",
    "    print 'Not attaching ephemerides and pointing info for calstars.'\n",
    "    \n",
    "    \n",
    "    # STEP 3: Make hot pixel mask (if need to) and/or correct for hot pixels in rf-off images\n",
    "    \n",
    "    pix_correct_query = raw_input('Do you want to correct for hot pixels and cosmic rays? y or n ')\n",
    "    if pix_correct_query == 'y':\n",
    "        hot_pixel_mask_query = raw_input('Does this dataset have a hot pixel mask made already (if y will correct for hot/bad pixels, if n will make new one based on flat list and then correct for hot/bad pixels)? y or n')\n",
    "        if hot_pixel_mask_query == 'y':\n",
    "            pixelmaskname = raw_input('What is the path+name of the pixel mask?')\n",
    "        else:\n",
    "            #If need to make pixel mask, make it from flat list\n",
    "            pixelmaskname = raw_input('What do you want the path+name of the pixel mask to be?')\n",
    "            print 'Making pixel mask...'\n",
    "            pix_mask_maker(flatlist, flatdirectory,pixelmaskname)\n",
    "\n",
    "        print 'Correcting pixels and cosmic rays in RF-off images...'\n",
    "        #Once hot pixel mask exists and has been saved to pixelmaskname, use it to correct for hot pixels AND correct for cosmic rays for rf-off images:\n",
    "        pixel_corrector(sciencedirectory,sciencelist,pixelmaskname,0) #science images\n",
    "        \n",
    "        print 'Not correcting pixels and cosmic eays in RF-off flats.'\n",
    "        #pixel_corrector(flatdirectory,flatlist,pixelmaskname,0) #flats\n",
    "    \n",
    "    else:\n",
    "        print 'Not correcting hot pixels or cosmic rays in RF-off images.'\n",
    "    \n",
    "    # STEP 4: Once rf-off images are prepared, subtract them from rf-on images\n",
    "    \n",
    "    rfoff_query = raw_input('Would you like to RF-off subtract science images? y or n ')\n",
    "    if rfoff_query == 'y':\n",
    "        print 'RF-off subtracting science images...'\n",
    "        # First, science images\n",
    "        rf_off(sciencedirectory,sciencelist)\n",
    "    else:\n",
    "        print 'Not RF-off subtracting science images.'\n",
    "    \n",
    "    \n",
    "    # STEP 5: Correct subtracted RF-on images for cosmic rays and hot pixels\n",
    "    \n",
    "    if pix_correct_query == 'y':\n",
    "        print 'Correcting pixels and cosmic rays in RF-on images...'\n",
    "        pixel_corrector(sciencedirectory,sciencelist,pixelmaskname,1) #science images\n",
    "        print 'Not correcting pixels and cosmic eays in RF-on flats.'\n",
    "        #pixel_corrector(flatdirectory,flatlist,pixelmaskname,1) #flats\n",
    "    else:\n",
    "        print 'Not correcting pixels or cosmic rays in RF-on images.'\n",
    "    \n",
    "    \n",
    "    # STEP 6: Divide flats and science images by exposure time (to prep for flat division)\n",
    "    # Science images:\n",
    "    exptime_divide_query = raw_input('Do you want to divide SCIENCE IMAGES by exposure time? y or n ')\n",
    "    if exptime_divide_query == 'y':\n",
    "        print 'Dividing science images by exposure time...'\n",
    "        div_by_exptime(sciencedirectory,sciencelist)\n",
    "    \n",
    "    # STEP 7: Flat divide\n",
    "    flat_query = raw_input('Do you want to divide by flats? y or n ')\n",
    "    if flat_query == 'y':\n",
    "        print 'Flat dividing...'\n",
    "        # Note: This flat division program does not use any fringe correction. Just matches flats by wavelength. \n",
    "        flat_div(sciencedirectory,sciencelist,flatdirectory,flatlist)\n",
    "    else:\n",
    "        print 'Not dividing by flats.'\n",
    "    \n",
    "    print 'Pipeline complete! Images have been eph-attached, RF-off subbed, exp time divided, flat divided.'\n",
    "    print 'Be sure to manually look through images to make sure they look okay, that there\\'s no faulty RF-off subtraction, etc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''CAL STAR VERSION, WITH QUERIES ANSWERED for MARCH 2017'''\n",
    "#sciencelist = path+name of calstar cube\n",
    "#sciencedirectory = path of calstar data location\n",
    "\n",
    "#Queries answered:\n",
    "# y to correcting wavelength\n",
    "# y to correcting hot pixels\n",
    "# y to already having a mask\n",
    "# pixel mask: /Users/dahlek/Desktop/march2017/pix_mask\n",
    "\n",
    "\n",
    "def reduce_datacube_calstar_queriesanswered(sciencelist,sciencedirectory,flatlist,flatdirectory):\n",
    "    \n",
    "    #STEP 1: Correct wavelength (or not)\n",
    "    \n",
    "    wl_correction_query = 'y' \n",
    "    #raw_input('Is this dataset from before January 2018 (Does the wavelength need to be corrected)? y or n')\n",
    "    #ds_corr_query = raw_input('Do you want to correct for the Doppler shift resulting from the moition of the planet? y or n ')\n",
    "    ds_corr_query = 'n'\n",
    "    \n",
    "    if wl_correction_query == 'y':\n",
    "        print 'Correcting wavelength...'\n",
    "        #If wavelength needs to be corrected since it was taken before \n",
    "        #correct science images\n",
    "        wavelength_corrector(sciencelist,sciencedirectory)\n",
    "        #correct flats\n",
    "        wavelength_corrector(flatlist,flatdirectory)\n",
    "    elif wl_correction_query == 'n':\n",
    "        print 'Not correcting wavelength.'\n",
    "        \n",
    "    if ds_corr_query == 'y':\n",
    "        print 'Correcting wavelength for Doppler shift...'\n",
    "        doppler_shift_corr(sciencelist,sciencedirectory)\n",
    "    else:\n",
    "        print 'Not correcting for Doppler shift.'\n",
    "        \n",
    "    # STEP 2: Attach ephemerides\n",
    "    print 'Not attaching ephemerides and pointing info for calstars.'\n",
    "    \n",
    "    \n",
    "    # STEP 3: Make hot pixel mask (if need to) and/or correct for hot pixels in rf-off images\n",
    "    pix_correct_query = 'y'\n",
    "    #raw_input('Do you want to correct for hot pixels and cosmic rays? y or n ')\n",
    "    if pix_correct_query == 'y':\n",
    "        hot_pixel_mask_query = 'y'\n",
    "        #raw_input('Does this dataset have a hot pixel mask made already (if y will correct for hot/bad pixels, if n will make new one based on flat list and then correct for hot/bad pixels)? y or n')\n",
    "        if hot_pixel_mask_query == 'y':\n",
    "            pixelmaskname = '/Users/dahlek/Desktop/march2017/pix_mask_march2017' #raw_input('What is the path+name of the pixel mask?')\n",
    "        else:\n",
    "            #If need to make pixel mask, make it from flat list\n",
    "            pixelmaskname = raw_input('What do you want the path+name of the pixel mask to be?')\n",
    "            print 'Making pixel mask...'\n",
    "            pix_mask_maker(flatlist, flatdirectory,pixelmaskname)\n",
    "\n",
    "        print 'Correcting pixels and cosmic rays in RF-off images...'\n",
    "        #Once hot pixel mask exists and has been saved to pixelmaskname, use it to correct for hot pixels AND correct for cosmic rays for rf-off images:\n",
    "        pixel_corrector(sciencedirectory,sciencelist,pixelmaskname,0) #science images\n",
    "        \n",
    "        print 'Not correcting pixels and cosmic eays in RF-off flats.'\n",
    "        #pixel_corrector(flatdirectory,flatlist,pixelmaskname,0) #flats\n",
    "    \n",
    "    else:\n",
    "        print 'Not correcting hot pixels or cosmic rays in RF-off images.'\n",
    "    \n",
    "    \n",
    "    # STEP 4: Once rf-off images are prepared, subtract them from rf-on images\n",
    "    rfoff_query = 'y'\n",
    "    #raw_input('Would you like to RF-off subtract science images? y or n ')\n",
    "    if rfoff_query == 'y':\n",
    "        print 'RF-off subtracting science images...'\n",
    "        # First, science images\n",
    "        rf_off(sciencedirectory,sciencelist)\n",
    "    else:\n",
    "        print 'Not RF-off subtracting science images.'\n",
    "    \n",
    "    \n",
    "    # STEP 5: Correct subtracted RF-on images for cosmic rays and hot pixels\n",
    "    if pix_correct_query == 'y':\n",
    "        print 'Correcting pixels and cosmic rays in RF-on images...'\n",
    "        pixel_corrector(sciencedirectory,sciencelist,pixelmaskname,1) #science images\n",
    "        print 'Not correcting pixels and cosmic eays in RF-on flats.'\n",
    "        #pixel_corrector(flatdirectory,flatlist,pixelmaskname,1) #flats\n",
    "    else:\n",
    "        print 'Not correcting pixels or cosmic rays in RF-on images.'\n",
    "    \n",
    "    \n",
    "    \n",
    "    # STEP 6: Divide flats and science images by exposure time (to prep for flat division)\n",
    "    # Science images:\n",
    "    exptime_divide_query = 'y'\n",
    "    #raw_input('Do you want to divide SCIENCE IMAGES by exposure time? y or n ')\n",
    "    if exptime_divide_query == 'y':\n",
    "        print 'Dividing science images by exposure time...'\n",
    "        div_by_exptime(sciencedirectory,sciencelist)\n",
    "    exptime_divide_query_2 = 'n'\n",
    "    #raw_input('Do you want to divide FLATS by exposure time? y or n ')\n",
    "    if exptime_divide_query_2 == 'y':\n",
    "        # Flats:\n",
    "        print 'Dividing flats by exposure time...'\n",
    "        div_by_exptime(flatdirectory,flatlist)\n",
    "    \n",
    "    \n",
    "    # STEP 7: Flat divide\n",
    "    flat_query = 'y'\n",
    "    #raw_input('Do you want to divide by flats? y or n ')\n",
    "    if flat_query == 'y':\n",
    "        print 'Flat dividing...'\n",
    "        # Note: This flat division program does not use any fringe correction. Just matches flats by wavelength. \n",
    "        flat_div(sciencedirectory,sciencelist,flatdirectory,flatlist)\n",
    "    else:\n",
    "        print 'Not dividing by flats.'\n",
    "    \n",
    "    print 'Pipeline complete! Images have been eph-attached, RF-off subbed, exp time divided, flat divided.'\n",
    "    print 'Be sure to manually look through images to make sure they look okay, that there\\'s no faulty RF-off subtraction, etc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example input; would have to reduce each calstar cube by itself\n",
    "reduce_datacube_calstar('/Users/dahlek/Desktop/march2017/stars/star1','/Users/dahlek/Desktop/march2017/stars/','/Users/dahlek/Desktop/march2017/flatlist','/Users/dahlek/Desktop/march2017/flats/')\n",
    "reduce_datacube_calstar_queriesanswered('/Users/dahlek/Desktop/march2017/stars/star2','/Users/dahlek/Desktop/march2017/stars/','/Users/dahlek/Desktop/march2017/flatlist','/Users/dahlek/Desktop/march2017/flats/')\n",
    "reduce_datacube_calstar_queriesanswered('/Users/dahlek/Desktop/march2017/stars/star3','/Users/dahlek/Desktop/march2017/stars/','/Users/dahlek/Desktop/march2017/flatlist','/Users/dahlek/Desktop/march2017/flats/')\n",
    "reduce_datacube_calstar_queriesanswered('/Users/dahlek/Desktop/march2017/stars/star5','/Users/dahlek/Desktop/march2017/stars/','/Users/dahlek/Desktop/march2017/flatlist','/Users/dahlek/Desktop/march2017/flats/')\n",
    "reduce_datacube_calstar_queriesanswered('/Users/dahlek/Desktop/march2017/stars/star6','/Users/dahlek/Desktop/march2017/stars/','/Users/dahlek/Desktop/march2017/flatlist','/Users/dahlek/Desktop/march2017/flats/')\n",
    "reduce_datacube_calstar_queriesanswered('/Users/dahlek/Desktop/march2017/stars/star7','/Users/dahlek/Desktop/march2017/stars/','/Users/dahlek/Desktop/march2017/flatlist','/Users/dahlek/Desktop/march2017/flats/')\n",
    "reduce_datacube_calstar_queriesanswered('/Users/dahlek/Desktop/march2017/stars/star8','/Users/dahlek/Desktop/march2017/stars/','/Users/dahlek/Desktop/march2017/flatlist','/Users/dahlek/Desktop/march2017/flats/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
